{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script d'utilisation de l'API Légifrance\n",
    "Ce script rend possible l'utilisation de l'API Légifrance, disponible via PISTE. Nos requêtes permettent de constituer une base de données comprenant les nominations en cabinet ministériel sur l'année 2024, et visent à démontrer la faisabilité de ce projet. \n",
    "\n",
    "Néanmoins, un travail de grande ampleur a déjà été réalisé par Nathann Cohen dans le cadre du projet Jorfsearch. Nous employons donc sa base de données dans notre analyse principale afin d'avoir une plus grande plage historique (1990-2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG8QlG2-UvKs"
   },
   "source": [
    "## 1/ Mise en place\n",
    "Il nous faut dans un premier temps obtenir notre token : celui-ci s'obtient grâce aux identifiants générés sur le portail PISTE lorsqu'on a accepté les CGU de l'API Légifrance.\n",
    "\n",
    "**Étapes à suivre pour obtenir un token**\n",
    "- Créer un compte PISTE : [https://piste.gouv.fr/component/apiportal/registration]\n",
    "- Une fois connecté, trouver dans le menu horizontal API -> Consentements CGU API : accepter les CGU pour l'API Légifrance\n",
    "- Raccorder l'API à votre application sandbox : Applications -> sandbox, cliquer sur le bouton modifier l'application, accéder à la page de consentement, sélectionner Légifrance et valider. Appliquer les modifications. \n",
    "- Trouver les identifiants Oauth : Applications -> sélectionner l'application souhaitée -> trouver la section Oauth. Les renseigner en tant que client_id et client_secret dans le script suivant afin d'obtenir un identifiant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "weTp1S8BUvKs",
    "outputId": "0760aa21-eb7e-49f0-824b-efb4ae95fcb1"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to input client_id and client_secret : nous ne voulons pas hardcoded nos identifiants\n",
    "client_id = input(\"Enter your client_id: \")  # client_id generated by PISTE\n",
    "client_secret = input(\"Enter your client_secret: \")  # client_secret generated by PISTE\n",
    "\n",
    "url = \"https://sandbox-oauth.piste.gouv.fr/api/oauth/token\"\n",
    "payload = {\n",
    "    \"grant_type\": \"client_credentials\",\n",
    "    \"client_id\": client_id,\n",
    "    \"client_secret\": client_secret,\n",
    "    \"scope\": \"openid\"\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "# Store the access token in a variable\n",
    "access_token = None\n",
    "if response.status_code == 200:\n",
    "    access_token = response.json().get(\"access_token\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zxnu8ZnUvKt"
   },
   "source": [
    "## 2/ Accès à la documentation Swagger\n",
    "Afin de comprendre la structure des requêtes possibles, nous accédons à la documentation Swagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Kn6lU1jUvKt",
    "outputId": "2a0dbe03-372c-4a63-96a2-835ed249c62a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Charger la documentation Swagger depuis une URL\n",
    "url = \"https://github.com/user-attachments/files/17714249/Legifrance.json\"\n",
    "response = requests.get(url)\n",
    "swagger_doc = response.json()\n",
    "\n",
    "# Afficher des informations générales\n",
    "print(\"Titre:\", swagger_doc['info']['title'])\n",
    "print(\"Version:\", swagger_doc['info']['version'])\n",
    "print(\"Description:\", swagger_doc['info'].get('description', 'Pas de description disponible'))\n",
    "\n",
    "# Parcourir les chemins (endpoints)\n",
    "print(\"\\nEndpoints disponibles :\")\n",
    "for path, methods in swagger_doc['paths'].items():\n",
    "    print(f\"\\nPath : {path}\")\n",
    "    for method, details in methods.items():\n",
    "        print(f\"  Méthode : {method.upper()}\")\n",
    "        print(\"    Description :\", details.get('description', 'Pas de description disponible'))\n",
    "\n",
    "        # Afficher les paramètres de chaque méthode\n",
    "        if 'parameters' in details:\n",
    "            print(\"    Paramètres :\")\n",
    "            for param in details['parameters']:\n",
    "                param_type = param.get('type', 'inconnu')  # Définit le type à \"inconnu\" si la clé \"type\" n'existe pas\n",
    "                print(f\"      - {param['name']} (type: {param_type}) - {'Obligatoire' if param.get('required') else 'Optionnel'}\")\n",
    "\n",
    "        # Afficher les réponses possibles\n",
    "        print(\"    Réponses :\")\n",
    "        for status_code, response in details['responses'].items():\n",
    "            print(f\"      - Code {status_code}: {response.get('description', 'Pas de description')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snHTlV-ZUvKu"
   },
   "source": [
    "## 3/ Requêtes pour les prénoms au JORF\n",
    "Notre objectif est d'avoir pour l'année 2024 l'ensemble des nominations. Pour ce faire, nous procédons en deux temps : \n",
    "- Nous identifions d'abord l'ensemble des arrêtés de nomination à l'aide de leur identifiant (NOR).\n",
    "- Pour chacun de ces NOR, nous identifions nom, prénom, poste, ministre, ministère et date de début. Ces informations n'ayant pas de tag, il est nécessaire de mettre des règles de syntaxes afin de les identifier. \n",
    "\n",
    "\n",
    "Voici, par exemple, le contenu d'un arrêté de nomination tel que nous l'obtenons via une requête pour un NOR donné :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nf5X15FRUvKu",
    "outputId": "dc189261-999f-43be-913a-c3cb73ee683a"
   },
   "outputs": [],
   "source": [
    "url = \"https://sandbox-api.piste.gouv.fr/dila/legifrance/lf-engine-app/consult/getJoWithNor/\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Afin de comprendre le format d'un output de nomination, utilisons le NOR d'une nomination donnée\n",
    "payload = {\n",
    "    \"nor\": \"ECOP2427670A\"\n",
    "}\n",
    "\n",
    "\n",
    "# Envoi de la requête\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "# Vérification et affichage du résultat\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(data)  # Affiche le contenu brut de la réponse pour analyse\n",
    "else:\n",
    "    print(f\"Erreur {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTPclWu7UvKu"
   },
   "source": [
    "Désormais, grâce au module search, nous identifions l'ensemble des nominations de l'année 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqB1DVH-UvKv",
    "outputId": "7c0bf69e-643e-4923-d107-44e6a9f2a990"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://sandbox-api.piste.gouv.fr/dila/legifrance/lf-engine-app/search/\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload_template = {\n",
    "    \"recherche\": {\n",
    "        \"filtres\": [\n",
    "            {\n",
    "                \"valeurs\": [\"ARRETE\"],\n",
    "                \"facette\": \"NATURE\"\n",
    "            },\n",
    "            {\n",
    "                \"dates\": {\n",
    "                    \"start\": \"2024-01-01\",\n",
    "                    \"end\": \"2024-12-31\"\n",
    "                },\n",
    "                \"facette\": \"DATE_SIGNATURE\"\n",
    "            }\n",
    "        ],\n",
    "        \"sort\": \"SIGNATURE_DATE_DESC\",\n",
    "        \"fromAdvancedRecherche\": False,\n",
    "        \"secondSort\": \"ID\",\n",
    "        \"champs\": [\n",
    "            {\n",
    "                \"criteres\": [\n",
    "                    {\"valeur\": \"cabinet\", \"operateur\": \"ET\", \"typeRecherche\": \"TOUS_LES_MOTS_DANS_UN_CHAMP\"},\n",
    "                    {\"valeur\": \"ministre\", \"operateur\": \"ET\", \"typeRecherche\": \"TOUS_LES_MOTS_DANS_UN_CHAMP\"}\n",
    "                ],\n",
    "                \"operateur\": \"ET\",\n",
    "                \"typeChamp\": \"TITLE\"\n",
    "            }\n",
    "        ],\n",
    "        \"pageSize\": 100,\n",
    "        \"operateur\": \"ET\",\n",
    "        \"typePagination\": \"DEFAUT\",\n",
    "        \"pageNumber\": 1\n",
    "    },\n",
    "    \"fond\": \"LODA_DATE\"\n",
    "}\n",
    "\n",
    "\n",
    "# Fetch all pages\n",
    "all_nors = []\n",
    "page_number = 1\n",
    "\n",
    "while True:\n",
    "    payload_template[\"recherche\"][\"pageNumber\"] = page_number\n",
    "    response = requests.post(url, headers=headers, json=payload_template)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results = data.get('results', [])\n",
    "        \n",
    "        if not results:  # Break if there are no more results\n",
    "            break\n",
    "\n",
    "        # Extract NORs\n",
    "        nors = [item['nor'] for item in results]\n",
    "        all_nors.extend(nors)\n",
    "        \n",
    "        page_number += 1\n",
    "    else:\n",
    "        print(\"Error during request:\", response.status_code, response.text)\n",
    "        break\n",
    "\n",
    "print(\"All NORs for 2024:\", all_nors)\n",
    "print(f\"Total NORs retrieved: {len(all_nors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VsykdOGUvKv"
   },
   "source": [
    "Désormais, pour l'ensemble de ces arrêtés publiés au JORF, identifiés par les NOR, nous allons essayer de récupérer les informations souhaitées. Cela n'est pas partie facile : un même arrêté peut avoir une seule ou plusieurs nominations, et la formule employée change selon le ministre qui la rédige, ou, vraisemblablement, sa bonne humeur. \n",
    "\n",
    "Nous optons donc pour un regex avec une structure par groupe, en essayant d'être le plus flexible. Par exemple, le genre est donné par la présence de M. ou Mme, et le prénom est le mot (éventuellement composé) qui suit immédiatement M. ou Mme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMH_OaPaUvKx",
    "outputId": "1bcc90bc-30a1-430c-8939-a331fd84eed7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "# API details\n",
    "url = \"https://sandbox-api.piste.gouv.fr/dila/legifrance/lf-engine-app/consult/getJoWithNor/\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",  # il faut faire tourner le premier chunk pour avoir l'access token\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# List of NORs to process\n",
    "\n",
    "# Regex to extract nominee details\n",
    "regex = r\"(M\\.|Mme) ([\\w\\-]+) ([\\w\\-]+(?: [\\w\\-]+)?)(?:,| est nommé(e)?) (.*?)(?:,|:|;|\\s)?(?: à compter du ([\\d]{1,2} [^\\d]+ [\\d]{4}|\\d{1,2}/\\d{1,2}/\\d{4}))(?:,|:|;|\\n)?\"\n",
    "#r\"(M\\.|Mme) ([\\w\\-]+) ([\\w\\-]+(?: [\\w\\-]+)?)(?:,| est nommée?| est nommée?) (.*?)(?:,|:|;|\\s)?(?: à compter du ([\\d]{1,2} [^\\d]+ [\\d]{4}|\\d{1,2}/\\d{1,2}/\\d{4}))(?:,|:|;|\\n)?\"\n",
    "\n",
    "# Data collection\n",
    "all_nominees = []\n",
    "\n",
    "# Loop through each NOR\n",
    "for nor in all_nors:\n",
    "    payload = {\"nor\": nor}\n",
    "    try:\n",
    "        # Send the request\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # Extract details for each article\n",
    "            articles = data.get(\"articles\", [])\n",
    "            for article in articles:\n",
    "                content = article.get(\"content\", \"\")\n",
    "\n",
    "                # Apply regex to find matches\n",
    "                matches = re.findall(regex, content, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "                for match in matches:\n",
    "                    genre, prenom, nom, _, titre, date = match\n",
    "                    all_nominees.append({\n",
    "                        \"Genre\": genre,\n",
    "                        \"Prénom\": prenom,\n",
    "                        \"Nom\": nom,\n",
    "                        \"Titre\": titre.strip(),\n",
    "                        \"Date de début\": date.strip() if date else \"Non précisée\",\n",
    "                        \"NOR\": nor,\n",
    "                        \"Ministre\": re.search(r\"Fait le .*?<br/>(.*?)</p>\", data.get(\"signers\", \"\"), re.DOTALL).group(1).strip() if \"signers\" in data else \"Non spécifié\",\n",
    "                        \"Ministère\": re.search(r\"cabinet du (.*)|cabinet de la (.*)\", data.get(\"title\", \"\"), re.IGNORECASE).group(1) or re.search(r\"cabinet du (.*)|cabinet de la (.*)\", data.get(\"title\", \"\"), re.IGNORECASE).group(2) if re.search(r\"cabinet du (.*)|cabinet de la (.*)\", data.get(\"title\", \"\"), re.IGNORECASE) else \"Non spécifié\"\n",
    "                    })\n",
    "        elif response.status_code == 429:\n",
    "            # Handle rate-limiting\n",
    "            retry_after = int(response.headers.get(\"Retry-After\", 5))\n",
    "            print(f\"Rate limit hit. Retrying after {retry_after} seconds...\")\n",
    "            time.sleep(retry_after)\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Error {response.status_code} for NOR {nor}: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred for NOR {nor}: {e}\")\n",
    "\n",
    "    # Avoid hitting the API rate limit\n",
    "    time.sleep(0.3)  # Adjust sleep time based on your successful 429 handling\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_nominees)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erreurs parfois rencontrées** \n",
    "- Erreur 401 : unauthorized, vérifier que son token n'est pas périmé, sinon c'est sans doute les requêtes provenant des serveurs du SSP Cloud qui sont bloquées. Résolution : passer en local.\n",
    "- Erreur 429 : too many requests, modifier le temps entre chaque requête\n",
    "\n",
    "Si le script s'execute sans erreur (souvent en une vingtaine de secondes), une dernière étape de nettoyage est nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "## 1. Nettoyage\n",
    "def clean_titre_column(titre):\n",
    "    # Remove HTML elements\n",
    "    titre = re.sub(r'<.*?>', '', titre)\n",
    "    # Remove elements starting with 'à comp' and ending with '2024'\n",
    "    titre = re.sub(r'à comp.*?2024', '', titre, flags=re.DOTALL)\n",
    "    # Remove semicolons, colons, and commas\n",
    "    titre = re.sub(r'[;:,.]', '', titre)\n",
    "    # Strip extra whitespace\n",
    "    return titre.strip()\n",
    "\n",
    "# Apply the cleaning function to the 'Titre' column\n",
    "df['Titre'] = df['Titre'].apply(clean_titre_column)\n",
    "\n",
    "## 2. Enregistrement en csv\n",
    "df.to_csv('nominations_2024.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce nettoyage est, dans une certaine mesure, un cache-misère : on perd un certain nombre de nominations, particulièrement lorsque les arrêtés de nominations comportent un grand nombre de prénoms, répartis par pôle. C'est par exemple le cas dans cet arrêté [https://www.legifrance.gouv.fr/jorf/id/JORFTEXT000049010626].\n",
    "\n",
    "Néanmoins, cela permet d'avoir une base utilisable, certes incomplète. Nous l'enregistrons dans notre bucket sur le SSP Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAftkIZJUvKy",
    "outputId": "b844b449-8e08-4228-9e4a-caa8db39477c"
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "## 3. Envoi au bucket\n",
    "# Configurons la connection\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "\n",
    "# Détails de notre bucket et fichiers\n",
    "MY_BUCKET = \"sachanassensae\"\n",
    "fs.ls(MY_BUCKET)\n",
    "LOCAL_FILE = \"nominations_2024.csv\"\n",
    "\n",
    "# Enregistrons\n",
    "FILE_PATH_OUT_S3 = f\"{MY_BUCKET}/diffusion/nominations_2024.csv\"\n",
    "fs.put(LOCAL_FILE, FILE_PATH_OUT_S3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commandes afin de voir les NOR et le token utilisés\n",
    "print(access_token)\n",
    "print(all_nors)\n",
    "\n",
    "# Vérifions la présence du bucket\n",
    "fs.ls(f\"{MY_BUCKET}/diffusion\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
